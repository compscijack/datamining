{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation and Cleaning with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 1: Reading and accessing data\n",
    "\n",
    "### Read the survey response data\n",
    "\n",
    "To load data from a CSV file see the code below. The text file is in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('class_survey_data.csv')\n",
    "# To check the first few enteries of a dataframe\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For informationon how to save data to a text file, see here: https://towardsdatascience.com/how-to-export-pandas-dataframe-to-csv-2038e43d9c03 and check the documentation for various setting you can change for the save process https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To count the number of rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Number of rows: {len(data)}\")\n",
    "print(f\"Number of columns: {len(data.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get the dimensions directly by using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows and columns as a pair of values\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's show all column names\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's rename the columns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Timestamp': 'TIMESTAMP',\n",
    "                     'Group Name (use DNA if none)': 'GROUP_NAME',\n",
    "                     'What main industry have you worked in?': 'BACKGROUND_INDUSTRY',\n",
    "                     'How many years professional experience do you have?': 'BACKGROUND_YEARS_PROFESSIONAL',\n",
    "                     'How many years programming experience do you have?': 'BACKGROUND_YEARS_PROGRAMMING',\n",
    "                     'What key experiences do you have?': 'BACKGROUND_SKILLS',\n",
    "                     'Data management': 'IMPORT_DATA_MANAGEMENT',\n",
    "                     'Statistics': 'IMPORT_STATISTICS',\n",
    "                     'Visualisation': 'IMPORT_VISUALISATION',\n",
    "                     'Machine Learning & Data Mining': 'IMPORT_MACHINE_LEARNING',\n",
    "                     'Software Engineering': 'IMPORT_SOFTWARE_ENGINEERING',\n",
    "                     'Communication': 'IMPORT_COMMUNICATION',\n",
    "                     'How would you define Data Science in one sentence?': 'GOALS_DEFINITION',\n",
    "                     'What key skills do you want to develop?': 'GOALS_SKILLS',\n",
    "                     'What kind of role would you like to go into?': 'GOALS_ROLE',\n",
    "                     'What industry would you like to go into?': 'GOALS_INDUSTRY'},\n",
    "           inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access a single Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access a single column use square brackets with the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"GROUP_NAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check the unique values that appear in this column\n",
    "data[\"GROUP_NAME\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop a Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete a column or a row, use drop() as described here https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['GROUP_NAME'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access a single Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract a single row, you can use `loc()` or `iloc()`, and supply a row index number. An overview of the differences between these two approaches is here https://towardsdatascience.com/how-to-use-loc-and-iloc-for-selecting-data-in-pandas-bd09cb4c3d79<br>\n",
    "As a brief summary the format for `loc()` is:<br>\n",
    "    `loc(row_label/s, column label/s)` <br>\n",
    "If you want to select all rows or all columns, use a colon `:` for the row or columns. Take note of the location f the `:` inside `loc()` in the remaining examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.loc[20, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access a Single Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first method is to access via the index name and column name using `.loc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.loc[20, \"BACKGROUND_INDUSTRY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second method is to access via the row and column indexes using `.iloc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[20, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also intermix index and column name as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.index[20], 'BACKGROUND_INDUSTRY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use basic evaluations when extracting data from a `dataframe`, using the comparison operators such as `>` `<=` etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data for survey respondents who gave a score of 2 or less for the importance of statistics\n",
    "data.loc[data[\"IMPORT_STATISTICS\"] <= 2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing a Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also slice `dataframes` using the same approach as with strings, excep that there to slice whole rows out of the `dataframe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLICE ROWS - show data between the 4th and 6th respondents\n",
    "print(data.iloc[3:6, :])     # slice the dataframe by rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLICE COLUMNS\n",
    "data.loc[:, \"GOALS_DEFINITION\":\"GOALS_INDUSTRY\"]     # slice the dataframe by columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort All Rows by One Column (Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sort the columns\n",
    "data.sort_values(\"IMPORT_STATISTICS\", axis = 0) # sort by the 'IMPORT_STATISTICS' cloumn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: What is the third respondent's rating for communication as integer value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: replace the content of this cell with your Python solution\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 4: Cleaning the data\n",
    "\n",
    "### Formatting the column values\n",
    "\n",
    "`Counter` from the `collections` module is useful for quickly calculating frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check  the data type of all columns\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Print the unique values of all columns\n",
    "for column in data.columns:\n",
    "    print(column)\n",
    "    print(data[column].value_counts()[:10])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the timestamp column to datetime in format DD-MM-YYYY HH:MM:SS. \n",
    "# There are up to 6 datetime formats: \n",
    "# '%m/%d/%Y %H:%M:%S', '%m/%d/%Y %H:%M', '%d/%m/%Y %H:%M:%S', '%d/%m/%Y %H:%M', '%d/%m/%Y %H:%M:%S' and '%d/%m/%Y %H:%M'\n",
    "# We will use a for loop to iterate over the rows of the dataframe and address each possible format\n",
    "\n",
    "# Create a list of datatime formats to try\n",
    "US_formats = ['%m/%d/%Y %H:%M:%S', '%m/%d/%Y %H:%M', '%d/%m/%Y %H:%M:%S', '%d/%m/%Y %H:%M']\n",
    "UK_formats = ['%d/%m/%Y %H:%M:%S', '%d/%m/%Y %H:%M']\n",
    "format_to_use = '%d/%m/%Y %H:%M:%S'\n",
    "\n",
    "# Iterate over the rows then formats and do the format conversion\n",
    "for i, row in data.iterrows():\n",
    "    if i < 106: # The first 106 rows are in US format\n",
    "        for format in US_formats:\n",
    "            try:\n",
    "                data.loc[i, 'TIMESTAMP'] = datetime.strptime(row['TIMESTAMP'], format).strftime(format_to_use)\n",
    "                # Convert the column to format_to_use\n",
    "                data.loc[i, 'TIMESTAMP'] = datetime.strptime(row['TIMESTAMP'], format_to_use)  \n",
    "            except:\n",
    "                pass\n",
    "    else: # The rest of the rows are in UK format\n",
    "        for format in UK_formats:\n",
    "            try:\n",
    "                data.loc[i, 'TIMESTAMP'] = datetime.strptime(row['TIMESTAMP'], format).strftime(format_to_use)\n",
    "                # Convert the column to format_to_use\n",
    "                data.loc[i, 'TIMESTAMP'] = datetime.strptime(row['TIMESTAMP'], format_to_use)  \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# Check the TIMESTAMP column\n",
    "data['TIMESTAMP'].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BACKGROUND_INDUSTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode any value not in the list of values as 'Other'\n",
    "allowed_values = ['Education and Training', 'Financial and Insurance Services', 'Information Technology',\n",
    "                  'Manufacturing', 'Media and Communications', 'Mining', 'Retail', 'ScientiIc Research',\n",
    "                  'Utilities']\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    for column in ['BACKGROUND_INDUSTRY', 'GOALS_INDUSTRY']:\n",
    "        if row[column] not in allowed_values:\n",
    "            data.loc[i, column] = 'Other'\n",
    "        if row[column] == 'ScientiIc Research':\n",
    "            data.loc[i, column] = 'Scientific Research'\n",
    "\n",
    "# Check the values in the BACKGROUND_INDUSTRY column\n",
    "print('BACKGROUND_INDUSTRY')\n",
    "print('-------------------')\n",
    "print(data['BACKGROUND_INDUSTRY'].value_counts())\n",
    "print('\\n')\n",
    "\n",
    "# Check the values in the BACKGROUND_INDUSTRY column\n",
    "print('GOALS_INDUSTRY')\n",
    "print('-------------------')\n",
    "print(data['GOALS_INDUSTRY'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BACKGROUND_YEARS_PROFESSIONAL and BACKGROUND_YEARS_PROGRAMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BACKGROUND_YEARS_PROFESSIONAL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_exp_columns(data, columns, default_value):\n",
    "    \n",
    "    '''This function cleans the values in the two experience columns\n",
    "    \n",
    "    Inputs:\n",
    "    data: the dataframe\n",
    "    columns: the columns to be cleaned\n",
    "    default_value: the value to be used for the default value\n",
    "\n",
    "    Output:\n",
    "    data: the dataframe with the cleaned column\n",
    "    ''' \n",
    "\n",
    "    special_values= {'1 year' : 1.0, \n",
    "                     '2years' : 2.0, \n",
    "                     '2 years': 2.0,\n",
    "                     '2 years accountant': 2.0, \n",
    "                     '3 years': 3.0,\n",
    "                     \"3year's in retail and Education area but not related this subject.\": 3.0,\n",
    "                     '6 years': 6.0,\n",
    "                     '8 years': 8.0,\n",
    "                     'no professional experience': 0.0,\n",
    "                     'none': 0.0,\n",
    "                     'Ten' : 10.0,\n",
    "                     '12+' : 12.0, \n",
    "                     'Half a year': 0.5,\n",
    "                     '0.5 year': 0.5,\n",
    "                     '4 months': 1/3, \n",
    "                     '6 months': 0.5, \n",
    "                     '6MONTHS': 0.5, \n",
    "                     '3 Months': 0.25, \n",
    "                     '1 month': 1/12}\n",
    "    \n",
    "    for i, row in data.iterrows():\n",
    "        for column in columns:\n",
    "            old_value = row[column] \n",
    "            if old_value in special_values.keys():\n",
    "                new_value = special_values[old_value]\n",
    "            else:\n",
    "                try:\n",
    "                    new_value = float(old_value)\n",
    "                except:\n",
    "                    new_value = default_value\n",
    "            data.loc[i, column] = new_value\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_VALUE = np.nan\n",
    "data = clean_exp_columns(data, ['BACKGROUND_YEARS_PROFESSIONAL', 'BACKGROUND_YEARS_PROGRAMMING'], DEFAULT_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BACKGROUND_YEARS_PROFESSIONAL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BACKGROUND_YEARS_PROGRAMMING'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *STOP PLEASE. THE FOLLOWING IS FOR THE NEXT EXERCISE. THANKS.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 3: Calculating descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting data\n",
    "\n",
    "`value_counts()` method in pandas is useful for quickly calculating frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution of communication importance ratings:\")\n",
    "print(\"-------------------------------------------------\")\n",
    "print(data['IMPORT_COMMUNICATION'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Calculate distribution of background and goal industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### TO DO: replace the content of this cell with your Python solution\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the mode\n",
    "\n",
    "We can also use `Counter` to calculate the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First calculate the frequencies (here we also sort the values)\n",
    "Communication_freqs = data['IMPORT_COMMUNICATION'].value_counts()\n",
    "Communication_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then calculate the mode by selecting the index of the maximum value\n",
    "print(\"Communication mode:\", Communication_freqs.idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We probably will need to calculate the _mode_ more than once. It hence is a good idea to define this as our a local function which we can later call with different parameters, depending on which data we would like to calculate the mode for, and without the need to repeat all its code again and again.\n",
    "\n",
    "In Python, one defines a local function with the **def** statement, followed by the function name and a list of arguments with which we can invoke a function later.\n",
    "\n",
    "Our own 'mode' function is introduced and used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a new 'mode' function\n",
    "def mode(data, column):\n",
    "    val_freqs = data[column].value_counts()\n",
    "    return val_freqs.idxmax()\n",
    "\n",
    "# example on how to use the 'mode' function\n",
    "print(\"Communication mode:\", mode(data, 'IMPORT_COMMUNICATION'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Calculate the mode of background and goal industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TO DO: replace the content of this cell with your Python solution\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *STOP PLEASE. THE FOLLOWING IS FOR THE NEXT EXERCISE. THANKS.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics with `numpy`\n",
    "\n",
    "We can calculate other descriptive statistics. `numpy` includes routines for measures of centrality and dispersion. Below we calculate descriptive statistics for professional and programming experience.\n",
    "\n",
    "Further detail: http://docs.scipy.org/doc/numpy/reference/routines.statistics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types of all columns\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the BACKGROUND_YEARS_PROFESSIONAL and BACKGROUND_YEARS_PROGRAMMING columns to float before we can calculate the descriptive statistics of these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the BACKGROUND_YEARS_PROFESSIONAL and BACKGROUND_YEARS_PROGRAMMING columns to float\n",
    "data['BACKGROUND_YEARS_PROFESSIONAL'] = data['BACKGROUND_YEARS_PROFESSIONAL'].astype(float)\n",
    "data['BACKGROUND_YEARS_PROGRAMMING'] = data['BACKGROUND_YEARS_PROGRAMMING'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now calculate the min, max, range, mean, standard deviation, median, 25th and 75th percentiles, and IQR\n",
    "for column in ['BACKGROUND_YEARS_PROFESSIONAL', 'BACKGROUND_YEARS_PROGRAMMING']:\n",
    "\n",
    "    print(column)\n",
    "    # grab values from the column\n",
    "    v = data[column].values\n",
    "    \n",
    "    # print the min\n",
    "    print(f\"* Min: {np.nanmin(v)}\")\n",
    "    # print max\n",
    "    print(f\"* Max: {np.nanmax(v)}\")\n",
    "    # print the range\n",
    "    print(f\"* Range: {np.nanmax(v)-np.nanmin(v)}\")\n",
    "    # print the mean\n",
    "    print(f\"* Mean: {np.nanmean(v)}\")    \n",
    "    # print the standard deviation\n",
    "    print(f\"* Standard deviation: {np.nanstd(v)}\")\n",
    "    # print the median\n",
    "    print(f\"* Median: {np.nanmedian(v)}\")\n",
    "    # print the 25th and 75th percentiles\n",
    "    q1 = np.nanpercentile(v, 25)\n",
    "    print(f\"* 25th percentile (Q1): {q1}\")\n",
    "    q3 = np.nanpercentile(v, 75)\n",
    "    print(f\"* 75th percentile (Q3): {q3}\")\n",
    "    # print the IQR\n",
    "    iqr = q3-q1\n",
    "    print(f\"* IQR: {iqr}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the cleaned data to a new csv file\n",
    "data.to_csv('class_survey_data_cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *STOP PLEASE. THE FOLLOWING IS FOR THE NEXT EXERCISE. THANKS.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 4: Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the missing values in each column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing value distribution using missingno library\n",
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print rows with more than one missing value\n",
    "data[data.isnull().sum(axis=1) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with more than one missing value\n",
    "data = data[data.isnull().sum(axis=1) <= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values in BACKGROUND_YEARS_PROFESSIONAL with the median\n",
    "data['BACKGROUND_YEARS_PROFESSIONAL'].fillna(data['BACKGROUND_YEARS_PROFESSIONAL'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values in BACKGROUND_YEARS_PROGRAMMING with the mean\n",
    "data['BACKGROUND_YEARS_PROGRAMMING'].fillna(data['BACKGROUND_YEARS_PROGRAMMING'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values in the BACKGROUND_SKILLS column with 'None'\n",
    "data['BACKGROUND_SKILLS'].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the missing values in each column\n",
    "data.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
